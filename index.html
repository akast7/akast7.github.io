<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Akhil V. Kasturi - PhD Candidate</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- 
        Chosen Palette: "Warm Neutrals" - A clean and professional palette with a light slate background, dark text for readability, and a subtle cyan accent for links and highlights.
        Application Structure Plan: The SPA is structured thematically to tell a compelling story. It begins with a clear "About Me" mission statement. The core research is broken into three thematic sections (Multimodal AI, Medical Vision, Immersive Training) using interactive cards to allow users to drill down into details without being overwhelmed. This is followed by a comprehensive, filterable publications list. This structure prioritizes user-driven exploration over a simple chronological list, making the content more digestible and impactful for recruiters and academics.
        Visualization & Content Choices: 
        - About Me: Simple, elegant text block. Goal: Establish expertise and mission. Method: HTML/Tailwind.
        - Research Projects: Interactive cards. Goal: Showcase key projects and their impact. Method: HTML/Tailwind with JS for toggleable details. Interaction: Users can click "Details" to see more, preventing initial information overload.
        - Publications: Filterable list. Goal: Provide a comprehensive academic record that is easy to navigate. Method: HTML/Tailwind with JS for filtering. Interaction: Users can click year buttons to instantly filter the list, making it easy to find recent work.
        CONFIRMATION: NO SVG graphics used. NO Mermaid JS used.
    -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc; /* slate-50 */
        }
        .active-filter {
            background-color: #0891b2; /* cyan-600 */
            color: white;
        }
    </style>
</head>
<body class="text-slate-800">

    <div class="max-w-4xl mx-auto p-4 sm:p-6 lg:p-8">

        <!-- Header Section -->
        <header class="text-center mb-12">
            <img src="assets/profile.jpg" alt="Akhil V. Kasturi" class="w-52 h-52 rounded-full mx-auto mb-4 border-4 border-white shadow-lg">
            <h1 class="text-4xl font-bold text-slate-900">Akhil V. Kasturi</h1>
            <p class="text-xl text-cyan-700 mt-2">PhD Candidate, University of Rochester</p>
            <nav class="mt-6 flex justify-center space-x-4 sm:space-x-6 text-sm sm:text-base">
                <a href="#about" class="text-slate-600 hover:text-cyan-700 transition">About</a>
                <a href="#research" class="text-slate-600 hover:text-cyan-700 transition">Research</a>
                <a href="#publications" class="text-slate-600 hover:text-cyan-700 transition">Publications</a>
            </nav>
        </header>

        <main>
            <!-- About Me Section -->
            <section id="about" class="mb-16 bg-white p-8 rounded-lg shadow-sm">
                <h2 class="text-2xl font-bold text-slate-900 mb-4">About Me</h2>
                <div class="space-y-4 text-slate-700 leading-relaxed">
                    <p>
                        I am a PhD candidate at the University of Rochester, where my research operates at the intersection of <strong>artificial intelligence, medical imaging, and clinical decision-making</strong>. I am advised by Prof. Axel Wismüller and am a member of the <strong>Wismüller Lab (AI in Radiology Laboratory)</strong>.
                    </p>
                    <p>
                        I’m driven by the potential of AI to transform disease diagnosis and prediction—enabling earlier, more accurate, and personalized care. My research focuses on developing reliable deep learning tools that utilize <strong>multimodal data</strong>, integrating medical imaging with clinical text and patient history to solve high-stakes challenges. I am particularly interested in how foundational models, including transformers and vision-language models, can be adapted for prognostication, diagnostic report generation, and immersive medical training. My work has been recognized with honors including the <strong>Best Scientific Poster Award</strong> at the SPIE Medical Imaging conference.
                    </p>
                    <p>
                        Previously, I graduated from Western University with an M.Eng. in Signal & Image Processing and from Fanshawe College with a Master's in Project Management. During my time there, I conducted research at the National Centre for Audiology, where I developed the core machine learning and software systems for an embedded patient simulator robot.
                    </p>
                     <p>Please feel free to get in touch!</p>
                </div>
            </section>

            <!-- Research Highlights Section -->
            <section id="research" class="mb-16">
                <h2 class="text-2xl font-bold text-slate-900 mb-6 text-center">Research Highlights</h2>
                <div id="research-grid" class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <!-- Research cards will be injected here by JavaScript -->
                </div>
            </section>

            <!-- Publications Section -->
            <section id="publications" class="bg-white p-8 rounded-lg shadow-sm">
                <h2 class="text-2xl font-bold text-slate-900 mb-4">Research & Publications</h2>
             

                <div class="flex justify-center space-x-2 mb-8">
                    <button class="filter-btn active-filter px-4 py-2 text-sm font-medium rounded-full transition" data-year="all">All</button>
                    <button class="filter-btn px-4 py-2 text-sm font-medium rounded-full transition bg-slate-200 hover:bg-slate-300" data-year="2025">2025</button>
                    <button class="filter-btn px-4 py-2 text-sm font-medium rounded-full transition bg-slate-200 hover:bg-slate-300" data-year="2024">2024</button>
                </div>

                <div id="publications-list" class="space-y-6">
                    <!-- Publications will be injected here by JavaScript -->
                </div>
            </section>
        </main>

        <!-- Footer -->
        <footer class="text-center mt-16 py-6 border-t border-slate-200">
            <div class="flex justify-center items-center space-x-6">
                 <a href="mailto:akasturi@ur.rochester.edu" class="text-slate-500 hover:text-cyan-700 transition">Email</a>
                 <a href="#" class="text-slate-500 hover:text-cyan-700 transition">CV</a>
                 <a href="https://www.linkedin.com/in/akhil-v-k-21069711b/" target="_blank" rel="noopener noreferrer" class="text-slate-500 hover:text-cyan-700 transition">LinkedIn</a>
                 <a href="#" class="text-slate-500 hover:text-cyan-700 transition">Google Scholar</a>
            </div>
            <p class="text-xs text-slate-400 mt-4">&copy; 2025 Akhil V. Kasturi</p>
        </footer>

    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            
            const researchData = [
                {
                    title: "Multimodal AI for Clinical Prognostication",
                    project: "CLAIR",
                    description: "Developed a novel multimodal framework integrating CT imaging and clinical data with a cross-attention mechanism. The model enables accurate neurological prognostication within 24 hours post-cardiac arrest, a significant improvement over the 72-hour clinical standard, achieving a state-of-the-art AUC-ROC of 0.94.",
                    tags: ["Multimodal AI", "Transformers", "Clinical AI"]
                },
                {
                    title: "Generative AI for Radiology Reporting",
                    project: "BioVLF-T",
                    description: "Architected a temporal vision-language framework that leverages historical patient data to generate contextually-aware radiology reports. This approach more closely mimics a radiologist's diagnostic workflow and improved CIDEr scores by over 1000%.",
                    tags: ["Generative AI", "VLM", "NLP"]
                },
                {
                    title: "AI for Medical Vision & Diagnostics",
                    project: "ETT-LDx",
                    description: "Designed and validated a suite of transformer-based models for the precise detection, segmentation, and placement verification of anatomical landmarks and medical devices in chest radiographs, outperforming existing industry standards on key accuracy metrics.",
                    tags: ["Computer Vision", "Segmentation", "Transformers"]
                },
                 {
                    title: "Immersive Medical Education & Training",
                    project: "BrainScale VR",
                    description: "Created a VR environment for medical training that facilitates interactive examination of 3D MRI brain scans. The platform integrates AI-assisted segmentation (UNETR) and a conversational LLM agent to provide an immersive, hands-on learning experience.",
                    tags: ["VR/AR", "3D Segmentation", "LLM"]
                }
            ];

            const publicationsData = [
                {
                    year: 2025,
                    title: "CLAIR: Rewriting the Prognostic Timeline: Al Integration of Brain Imaging and Clinical Data Enables Early Post-Arrest Decisions",
                    authors: "<strong>Akhil Kasturi</strong>, Ashley R. Proctor, Ali Vosoughi, et. al.",
                    venue: "<em>Under Review, npj Digital Medicine</em>",
                    links: { paper: "Submitted at NPJ Digital medicine (Under review)", code: "#" }
                },
                {
                    year: 2025,
                    title: "BioVLF-T: A Temporal Framework for Radiology Report Generation using Pre-Trained Vision Language Foundational Models",
                    authors: "<strong>Akhil Kasturi</strong>, Ali Vosoughi, Nathan Hadjiyski, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2025</em>",
                    links: { paper: "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13410/134100W/BioVLM-T--A-temporal-framework-for-radiology-report-generation/10.1117/12.3047498.full?webSyncID=d49a2853-1ab0-d3a6-b03c-97c009b6bcd7&sessionGUID=46b80d8e-8abe-eaed-6ae0-5c117aac5a91" }
                },
                {
                    year: 2025,
                    title: "ETT-LDx: Transformer-based Landmark Detection system for Endotracheal Tube Placement Verification in Chest Radiographs",
                    authors: "<strong>Akhil Kasturi</strong>, Ali Vosoughi, Nathan Hadjiyski, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2025</em>",
                    links: { paper: "#" }
                },
                {
                    year: 2025,
                    title: "BrainScale VR: VR-Enabled Foundational Vision Language Models for Medical Training",
                    authors: "<strong>Akhil Kasturi</strong> & Adma Gama-Krummel",
                    venue: "<em>Project Report, University of Rochester, 2025</em>",
                    links: { project: "#", code: "#" }
                },
                {
                    year: 2024,
                    title: "Anatomical Landmark Detection in Chest X-Rays using Transformer-Based Networks",
                    authors: "<strong>Akhil Kasturi</strong>, Ali Vosoughi, Nathan Hadjiyski, Larry Stockmaster, William J. Sehnert, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2024</em>",
                    links: { paper: "#" }
                },
                {
                    year: 2024,
                    title: "Segmentation of Catheter Tubes and Lines in Chest X-Rays using Deep Learning Models",
                    authors: "<strong>Akhil Kasturi</strong>, Ali Vosoughi, Nathan Hadjiyski, Larry Stockmaster, William J. Sehnert, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2024</em>",
                    links: { paper: "#" }
                },
                {
                    year: 2024,
                    title: "Classification of Endotracheal Tube Position in Chest X-Rays Images",
                    authors: "<strong>Akhil Kasturi</strong>, Ali Vosoughi, Nathan Hadjiyski, Larry Stockmaster, William J. Sehnert, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2024</em>",
                    links: { paper: "#" }
                },
                {
                    year: 2024,
                    title: "Enhancing Graph Attention Neural Network Performance for Marijuana Consumption Classification through Large-scale Augmented Granger Causality (lsAGC) Analysis of Functional MR Images",
                    authors: "Ali Vosoughi, <strong>Akhil Kasturi</strong>, and Axel Wismüller",
                    venue: "<em>SPIE Medical Imaging, 2024</em>",
                    links: { paper: "#" }
                }
            ];

            const researchGrid = document.getElementById('research-grid');
            researchData.forEach(item => {
                const card = document.createElement('div');
                card.className = 'bg-white p-6 rounded-lg shadow-sm hover:shadow-lg transition-shadow duration-300';
                
                let tagsHtml = item.tags.map(tag => `<span class="inline-block bg-cyan-100 text-cyan-800 text-xs font-medium mr-2 px-2.5 py-0.5 rounded-full">${tag}</span>`).join('');

                card.innerHTML = `
                    <h3 class="text-lg font-bold text-slate-900">${item.title}</h3>
                    <p class="text-sm font-semibold text-cyan-700 mb-3">${item.project}</p>
                    <div class="flex flex-wrap gap-2 mb-4">${tagsHtml}</div>
                    <p class="text-slate-600 text-sm leading-relaxed">${item.description}</p>
                `;
                researchGrid.appendChild(card);
            });

            const publicationsList = document.getElementById('publications-list');
            function renderPublications(filterYear = 'all') {
                publicationsList.innerHTML = '';
                const filteredData = filterYear === 'all' ? publicationsData : publicationsData.filter(p => p.year == filterYear);

                filteredData.forEach(pub => {
                    const item = document.createElement('div');
                    item.className = 'publication-item';
                    item.dataset.year = pub.year;

                    let linksHtml = Object.entries(pub.links).map(([name, url]) => 
                        `<a href="${url}" target="_blank" rel="noopener noreferrer" class="text-cyan-600 hover:text-cyan-800 font-medium capitalize">${name}</a>`
                    ).join(' | ');

                    item.innerHTML = `
                        <p class="font-semibold text-slate-800">${pub.title}</p>
                        <p class="text-sm text-slate-600 my-1">${pub.authors}</p>
                        <p class="text-sm text-slate-500">${pub.venue}</p>
                        <div class="text-sm mt-1">${linksHtml}</div>
                    `;
                    publicationsList.appendChild(item);
                });
            }

            const filterButtons = document.querySelectorAll('.filter-btn');
            filterButtons.forEach(button => {
                button.addEventListener('click', () => {
                    filterButtons.forEach(btn => btn.classList.remove('active-filter', 'bg-slate-200', 'hover:bg-slate-300'));
                    
                    button.classList.add('active-filter');
                    filterButtons.forEach(btn => {
                        if (!btn.classList.contains('active-filter')) {
                             btn.classList.add('bg-slate-200', 'hover:bg-slate-300');
                        }
                    });

                    renderPublications(button.dataset.year);
                });
            });

            renderPublications();
        });
    </script>
</body>
</html>
